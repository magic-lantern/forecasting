{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorations in how to improve performance\n",
    "\n",
    "Calculating counts based on common spellings/pronunciations of similar names is very slow look at optimizing/parallelizing.\n",
    "\n",
    "* see: https://stackoverflow.com/questions/26187759/parallelize-apply-after-pandas-groupby\n",
    "* potentially look at https://github.com/jmcarpenter2/swifter\n",
    "* see realted blog post: https://medium.com/@jmcarpenter2/swiftapply-automatically-efficient-pandas-apply-operations-50e1058909f9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1924665, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('babynames.pickle', 'rb') as f:\n",
    "    orig_df = pickle.load(f)\n",
    "orig_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77092, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('names_beidermorse.pickle', 'rb') as f:\n",
    "    names = pickle.load(f)\n",
    "names.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.971319144000006 seconds\n",
      "(1152268, 2)\n"
     ]
    }
   ],
   "source": [
    "# this takes about 35 seconds\n",
    "start = timer()\n",
    "def f(name, bmset):\n",
    "    return pd.DataFrame(zip([name] * len(bmset), list(bmset)), columns=('name', 'beidermorse'))\n",
    "\n",
    "kv_names = pd.concat([f(n,b) for n, b in zip(names['name'], names['bmset'])])\n",
    "end = timer()\n",
    "print(end - start, 'seconds')\n",
    "print(kv_names.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup test dataset\n",
    "df = orig_df[orig_df.year == 1990].sample(frac=.01, random_state=2213).copy()\n",
    "#df = orig_df[orig_df.year == 1990].copy()\n",
    "df.sort_values(['year', 'sex', 'name'], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "start = timer()\n",
    "calc_sound_totals(alt)\n",
    "end = timer()\n",
    "print(end - start, 'seconds')\n",
    "# right now it takes ~54 seconds to process 500 randomly selected records\n",
    "# ~26 seconds to process 250 randomly selected records\n",
    "# 95% or so of time is spend in the first block \"out_n\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%lprun -f create_df_out_n calc_sound_totals(alt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is very slow look at optimizing/parallelizing\n",
    "# see: https://stackoverflow.com/questions/26187759/parallelize-apply-after-pandas-groupby\n",
    "# potentially look at https://github.com/jmcarpenter2/swifter\n",
    "#   see realted blog post: https://medium.com/@jmcarpenter2/swiftapply-automatically-efficient-pandas-apply-operations-50e1058909f9\n",
    "\n",
    "# process each row of dataframe\n",
    "def create_df_out_n(row):\n",
    "    # should do no further processing if this row has already been counted\n",
    "    if (row['counted'] == True):\n",
    "        return\n",
    "\n",
    "    # find matching names\n",
    "    #checklist = names[names.name == row['name']].beidermorse.values[0].split()\n",
    "    #find = lambda i: any(x in i for x in checklist)\n",
    "    #found = names[names.bmset.map(find)].name\n",
    "    # this new method takes about half the time - 15 seconds for 250 rows\n",
    "    #checklist = names[names.name == row['name']].bmset.values[0]\n",
    "    #found = kv_names[kv_names.beidermorse.isin(checklist)]['name'].unique()\n",
    "    \n",
    "    checklist = filt_names[filt_names.name == row['name']].beidermorse.values\n",
    "    found = filt_names[filt_names.beidermorse.isin(checklist)]['name'].unique()\n",
    "\n",
    "    # aggregate count, excluding counted names, for all found names into df_out_name\n",
    "    df_out.loc[(df_out.name == row['name']) &\n",
    "            (df_out.year == row.year) &\n",
    "            (df_out.sex == row.sex) ,\n",
    "            'alt_n'] = df_out[(df_out.name.isin(found)) & \n",
    "                           (df_out.year == row.year) &\n",
    "                           (df_out.sex == row.sex) &\n",
    "                           (df_out.counted == False)]['n'].sum()\n",
    "\n",
    "    # set counted flag for found names in group\n",
    "    # ? how to update just group ?\n",
    "    df_out.loc[(df_out.name.isin(found)) & (df_out.year == row.year) & (df_out.sex == row.sex), 'counted'] = True\n",
    "\n",
    "# create df_out_prop\n",
    "def create_df_out_prop(row, gsum):\n",
    "    df_out.loc[(df_out.name == row['name']) &\n",
    "            (df_out.year == row.year) &\n",
    "            (df_out.sex == row.sex) ,\n",
    "            'alt_prop'] = row['alt_n'] / gsum\n",
    "\n",
    "\n",
    "    \n",
    "def calc_sound_totals():\n",
    "    gdf = df_out.groupby(['year', 'sex'])\n",
    "    for name, group in gdf:\n",
    "        print('processing name:', name)\n",
    "        g = group.sort_values('n', ascending=False).copy()\n",
    "        g.apply(create_df_out_n, axis=1)\n",
    "\n",
    "    for name, group in gdf:\n",
    "        gsum = group['alt_n'].sum()\n",
    "        group.apply(create_df_out_prop, axis=1, args=(gsum,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing name: (1990.0, 'F')\n",
      "processing name: (1990.0, 'M')\n",
      "took: 2.747541163000001 seconds\n"
     ]
    }
   ],
   "source": [
    "df_out = df.copy()\n",
    "df_out['counted'] = False\n",
    "df_out['alt_n'] = 0\n",
    "df_out['alt_prop'] = 0.0\n",
    "\n",
    "filt_names = kv_names.merge(df, on='name')[['name', 'beidermorse']]\n",
    "\n",
    "#%lprun -f create_df_out_n calc_sound_totals()\n",
    "start = timer()\n",
    "out = calc_sound_totals()\n",
    "end = timer()\n",
    "print('took:', end - start, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# this is very slow look at optimizing/parallelizing\n",
    "# see: https://stackoverflow.com/questions/26187759/parallelize-apply-after-pandas-groupby\n",
    "# potentially look at https://github.com/jmcarpenter2/swifter\n",
    "#   see realted blog post: https://medium.com/@jmcarpenter2/swiftapply-automatically-efficient-pandas-apply-operations-50e1058909f9\n",
    "\n",
    "def calc_sound_totals(df_in):\n",
    "    df_out = df_in.copy()\n",
    "    df_out['counted'] = False\n",
    "    df_out['alt_n'] = 0\n",
    "    df_out['alt_prop'] = 0.0\n",
    "\n",
    "    # process each row of dataframe\n",
    "    def create_df_out_n(row):\n",
    "        # should do no further processing if this row has already been counted\n",
    "        if (row['counted'] == True):\n",
    "            return\n",
    "\n",
    "        # find matching names\n",
    "        checklist = names[names.name == row['name']].beidermorse.values[0].split()\n",
    "        find = lambda i: any(x in i for x in checklist)\n",
    "        found = names[names.bmset.map(find)].name\n",
    "\n",
    "        # aggregate count, excluding counted names, for all found names into df_out_name\n",
    "        df_out.loc[(df_out.name == row['name']) &\n",
    "                (df_out.year == row.year) &\n",
    "                (df_out.sex == row.sex) ,\n",
    "                'alt_n'] = df_out[(df_out.name.isin(found)) & \n",
    "                               (df_out.year == row.year) &\n",
    "                               (df_out.sex == row.sex) &\n",
    "                               (df_out.counted == False)]['n'].sum()\n",
    "\n",
    "        # set counted flag for found names in group\n",
    "        # ? how to update just group ?\n",
    "        df_out.loc[(df_out.name.isin(found)) & (df_out.year == row.year) & (df_out.sex == row.sex), 'counted'] = True\n",
    "\n",
    "    start = timer()\n",
    "    gdf = df_out.groupby(['year', 'sex'])\n",
    "    for name, group in gdf:\n",
    "        print('processing name:', name)\n",
    "        g = group.sort_values('n', ascending=False).copy()\n",
    "        g.apply(create_df_out_n, axis=1)\n",
    "\n",
    "    end = timer()\n",
    "    print('create out_n', end - start, 'seconds')\n",
    "    \n",
    "    # create df_out_prop\n",
    "    def create_df_out_prop(row):\n",
    "        df_out.loc[(df_out.name == row['name']) &\n",
    "                (df_out.year == row.year) &\n",
    "                (df_out.sex == row.sex) ,\n",
    "                'alt_prop'] = row['alt_n'] / gsum\n",
    "\n",
    "    start = timer()\n",
    "    for name, group in gdf:\n",
    "        gsum = group['alt_n'].sum()\n",
    "        group.apply(create_df_out_prop, axis=1)\n",
    "    end = timer()\n",
    "    print('create out_prop', end - start, 'seconds')\n",
    "\n",
    "    return df_out\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.2 ms ± 608 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "rn = 'Michael'\n",
    "checklist = names[names.name == rn].bmset.values[0]\n",
    "found = kv_names[kv_names.beidermorse.isin(checklist)]['name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 ms ± 697 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "rn = 'Michael'\n",
    "checklist = names[names.name == rn].beidermorse.values[0].split()\n",
    "find = lambda i: any(x in i for x in checklist)\n",
    "found = names[names.bmset.map(find)].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.6 ms ± 746 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "rn = 'Michael'\n",
    "checklist = kv_names[kv_names.name == rn].beidermorse\n",
    "found = kv_names[kv_names.beidermorse.isin(checklist)]['name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn = kv_names.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562 ms ± 10.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "rn = 'Michael'\n",
    "bm = kn[np.where(kn == rn)[0]][:,1]\n",
    "out = [kn[np.where(kn == x)[0]][:,0] for x in bm]\n",
    "found = np.unique(np.concatenate( out, axis=0 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ni = kv_names.set_index('name')\n",
    "bi = kv_names.set_index('beidermorse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 ms ± 1.57 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "rn = 'Michael'\n",
    "found = bi.loc[ni.loc[rn].beidermorse].name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338 ms ± 23.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "rn = 'Michael'\n",
    "checklist = kv_names[kv_names.name == rn].beidermorse\n",
    "found = kv_names.merge(checklist, on='beidermorse')['name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if I filter the list to just those in this year/group, performance is much improved.\n",
    "sub = kv_names.merge(df, on='name')[['name', 'beidermorse']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.23 ms ± 42 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "rn = 'Michael'\n",
    "checklist = sub[sub.name == rn].beidermorse.values\n",
    "found = sub[sub.beidermorse.isin(checklist)]['name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "text/plain": [
       "         1316 function calls (1296 primitive calls) in 0.029 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "   List reduced from 229 to 10 due to restriction <10>\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "        1    0.026    0.026    0.026    0.026 {pandas._libs.hashtable.ismember_object}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'nonzero' of 'numpy.ndarray' objects}\n",
       "        1    0.000    0.000    0.026    0.026 algorithms.py:407(<lambda>)\n",
       "      239    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
       "       16    0.000    0.000    0.000    0.000 dtypes.py:68(find)\n",
       "       47    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
       "       26    0.000    0.000    0.000    0.000 common.py:1845(_is_dtype_type)\n",
       "        1    0.000    0.000    0.029    0.029 {built-in method builtins.exec}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'unique' of 'pandas._libs.hashtable.StringHashTable' objects}\n",
       "        1    0.000    0.000    0.000    0.000 indexing.py:2575(maybe_convert_indices)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%prun -l 10 kv_names[kv_names.beidermorse.isin(['zYsDki'])]['name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "text/plain": [
       "         1392 function calls (1368 primitive calls) in 0.042 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "   List reduced from 228 to 10 due to restriction <10>\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "        1    0.040    0.040    0.040    0.040 {pandas._libs.hashtable.ismember_object}\n",
       "        1    0.000    0.000    0.040    0.040 algorithms.py:407(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'nonzero' of 'numpy.ndarray' objects}\n",
       "      254    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
       "       18    0.000    0.000    0.000    0.000 dtypes.py:68(find)\n",
       "       47    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
       "        1    0.000    0.000    0.042    0.042 {built-in method builtins.exec}\n",
       "     13/9    0.000    0.000    0.000    0.000 {built-in method numpy.array}\n",
       "       26    0.000    0.000    0.000    0.000 common.py:1845(_is_dtype_type)\n",
       "        1    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_2d_axis1_object_object}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checklist = kv_names[kv_names.name == 'Michael'].beidermorse\n",
    "%prun -l 10 kv_names[kv_names.beidermorse.isin(checklist)]['name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.3 ms ± 678 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sub = kv_names.merge(df, on='name')[['name', 'beidermorse']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
